{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAISHNAVI JAMDADE(TM39453)\n",
    "### HOMEWORK 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the file into numpy array of dimensions (60000,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertfunc(file):\n",
    "    arr = idx2numpy.convert_from_file(file)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=convertfunc('train-images.idx3-ubyte')\n",
    "y_train=convertfunc('train-labels.idx1-ubyte')\n",
    "X_test=convertfunc('t10k-images.idx3-ubyte')\n",
    "y_test=convertfunc('t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapefunc(array,rows,columns):\n",
    "    array=array.reshape(rows,columns)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=reshapefunc(X_train,60000,784)\n",
    "X_test=reshapefunc(X_test,10000,784)\n",
    "#y_train=reshapefunc(y_train,1,60000)\n",
    "#y_test=reshapefunc(y_test,1,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000,), (10000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape, y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using One hot label encoding for output labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000, 10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training data into Training and Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (18000, 784), (42000, 10), (18000, 10))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(inputs, hNeurons, oNeurons):\n",
    "\n",
    "    weights1=np.random.randn(inputs,hNeurons)*np.sqrt(1./inputs)    #784 rows 5 columns\n",
    "    bias1=np.zeros((1, hNeurons))*np.sqrt(1./inputs)\n",
    "    #hence x.w = 1,5 dimensions + bias [1,5]\n",
    "    weights2=np.random.randn(hNeurons,oNeurons)*np.sqrt(1./hNeurons)\n",
    "    #hence x.w= 5,10 dimensions + bias [1,10]\n",
    "    bias2= np.zeros((1, oNeurons))*np.sqrt(1./hNeurons)\n",
    "\n",
    "    #ouptut vecotr is going to be of dimensions [1,10] then softmax\n",
    "    #W1.shape , b1.shape, W2.shape, b2.shape\n",
    "    \n",
    "    return weights1, bias1, weights2, bias2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    act = 1. / (1. + np.exp(-z))\n",
    "    return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Activation function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef softmax(z):\\n    softact = np.exp(z - np.max(z, axis=1, keepdims=True))\\n    softact=softact/np.sum(softact, axis=1, keepdims=True)\\n    \\n    return softact\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalising the values:\n",
    "\n",
    "def softmax(z):\n",
    "    softact = np.exp(z)/np.sum(np.exp(z), axis=1,keepdims=True)                                       \n",
    "    return softact\n",
    "\n",
    "'''\n",
    "def softmax(z):\n",
    "    softact = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    softact=softact/np.sum(softact, axis=1, keepdims=True)\n",
    "    \n",
    "    return softact\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(X_train,W1,b1,W2,b2):\n",
    "    z1= np.dot(X_train,W1)+b1\n",
    "    h1=sigmoid(z1)\n",
    "    \n",
    "    z2=np.dot(h1,W2)+b2\n",
    "    output=softmax(z2)\n",
    "    return z1, h1, z2, output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(ypred,y_train):     \n",
    "    n_samples = y_train.shape[0]\n",
    "    L = (ypred-y_train)/n_samples\n",
    "    return L\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crossentropy(ypred,y_train):\n",
    "    L_sum = np.sum(np.multiply(y_train, np.log(ypred)))\n",
    "    num_samples = y_train.shape[0]\n",
    "    L = -(1./num_samples) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate Sigmoid Derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(h1):\n",
    "    deriv=h1*(1-h1)\n",
    "    return deriv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation Function to compute Gradient Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(h1,W2,ypred,y_train):\n",
    "    \n",
    "    #Calculate error\n",
    "    L=error(ypred,y_train)\n",
    "    \n",
    "    # z1, h1, z2, output\n",
    "    # z1, and z2 => dot products\n",
    "    # h1 and output => activations\n",
    "    change_output=L\n",
    "    #dL/dW2\n",
    "    delta_W2= np.dot(h1.T,change_output)\n",
    "    \n",
    "    #dL/db2\n",
    "    delta_b2= np.sum(change_output,axis=0,keepdims=True)\n",
    "    \n",
    "    #dL/dh1\n",
    "    delta_h1=np.dot(change_output,W2.T)\n",
    "\n",
    "    change_h1= delta_h1*sigmoid_derivative(h1)\n",
    "    \n",
    "    #dL/dW1\n",
    "    delta_W1= np.dot(X_train.T, change_h1)\n",
    "    \n",
    "    #dL/db1\n",
    "    delta_b1= np.sum(change_h1,axis=0,keepdims=True)\n",
    "    \n",
    "    return delta_W2, delta_b2, delta_W1, delta_b1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to update weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(alpha,W1,b1,W2,b2,delta_W2,delta_b2,delta_W1,delta_b1):\n",
    "    W2= W2- alpha*(delta_W2)\n",
    "    b2= b2 - alpha*(delta_b2)\n",
    "    W1= W1- alpha*(delta_W1)\n",
    "    b1=b1- alpha*(delta_b1)\n",
    "    \n",
    "    return W2,b2,W1,b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training():\n",
    "    hNeurons=128                               #hidden neuron\n",
    "    inputs=X_train.shape[1]                   #number of inputs\n",
    "    oNeurons=y_train.shape[1]\n",
    "    alpha= 0.05                        #learning rate\n",
    "    epochs=20\n",
    "    \n",
    "    #retriving the actual labels for y_train:\n",
    "    labely_train=np.argmax(y_train,axis=1)\n",
    "    \n",
    "    #initialize weights\n",
    "    W1, b1, W2, b2= initialize_weights(inputs,hNeurons,oNeurons)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        #feed forward\n",
    "        dotprod1, h1, dotprod2, output=feedforward(X_train,W1,b1,W2,b2)\n",
    "\n",
    "        #back propogate\n",
    "        delta_W2, delta_b2, delta_W1, delta_b1= backpropagation(h1,W2,output,y_train)\n",
    "        \n",
    "        #update weights using gradient descent\n",
    "        W2,b2,W1,b1=update_weights(alpha,W1,b1,W2,b2,delta_W2,delta_b2,delta_W1,delta_b1)\n",
    "\n",
    "        #again feed forward using updated weights\n",
    "        dotprod1, h1, dotprod2, output=feedforward(X_train,W1,b1,W2,b2)\n",
    "\n",
    "        #Calculating Total Loss\n",
    "        loss=crossentropy(output,y_train)                 # put in training func later\n",
    "        print(\"Epoch {}: training loss = {}\".format(i + 1,loss))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Retrieving the corresponding class labels:\n",
    "        labelpred=np.argmax(output,axis=1)\n",
    "        \n",
    "        #Training Accuracy:\n",
    "        accuracy = round((accuracy_score(labely_train, labelpred)*100),2)\n",
    "        print(\"Training Accuracy after Epoch {} : {}%\".format(i+1, accuracy))\n",
    "        \n",
    "    return W2,b2,W1,b1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss = 2.264849114083159\n",
      "Training Accuracy after Epoch 1 : 19.1%\n",
      "Epoch 2: training loss = 2.111996034878432\n",
      "Training Accuracy after Epoch 2 : 27.01%\n",
      "Epoch 3: training loss = 1.9817351900824909\n",
      "Training Accuracy after Epoch 3 : 36.39%\n",
      "Epoch 4: training loss = 1.8681003775486815\n",
      "Training Accuracy after Epoch 4 : 45.15%\n",
      "Epoch 5: training loss = 1.7716721255040744\n",
      "Training Accuracy after Epoch 5 : 50.83%\n",
      "Epoch 6: training loss = 1.687400304404762\n",
      "Training Accuracy after Epoch 6 : 55.29%\n",
      "Epoch 7: training loss = 1.611534765078037\n",
      "Training Accuracy after Epoch 7 : 59.0%\n",
      "Epoch 8: training loss = 1.5477284781053149\n",
      "Training Accuracy after Epoch 8 : 61.88%\n",
      "Epoch 9: training loss = 1.4917482292539586\n",
      "Training Accuracy after Epoch 9 : 64.22%\n",
      "Epoch 10: training loss = 1.4413936836517114\n",
      "Training Accuracy after Epoch 10 : 66.27%\n",
      "Epoch 11: training loss = 1.3961220430472117\n",
      "Training Accuracy after Epoch 11 : 68.09%\n",
      "Epoch 12: training loss = 1.354729698248073\n",
      "Training Accuracy after Epoch 12 : 69.63%\n",
      "Epoch 13: training loss = 1.3166208134661013\n",
      "Training Accuracy after Epoch 13 : 71.01%\n",
      "Epoch 14: training loss = 1.2816294350145891\n",
      "Training Accuracy after Epoch 14 : 72.36%\n",
      "Epoch 15: training loss = 1.2493191932404677\n",
      "Training Accuracy after Epoch 15 : 73.59%\n",
      "Epoch 16: training loss = 1.2191863423615934\n",
      "Training Accuracy after Epoch 16 : 74.54%\n",
      "Epoch 17: training loss = 1.1915182021178166\n",
      "Training Accuracy after Epoch 17 : 75.31%\n",
      "Epoch 18: training loss = 1.165227645809047\n",
      "Training Accuracy after Epoch 18 : 76.14%\n",
      "Epoch 19: training loss = 1.1406532606239208\n",
      "Training Accuracy after Epoch 19 : 76.79%\n",
      "Epoch 20: training loss = 1.1170377775911824\n",
      "Training Accuracy after Epoch 20 : 77.47%\n"
     ]
    }
   ],
   "source": [
    "W2,b2,W1,b1=training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our model on Validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(W2,b2,W1,b1,X_test,y_test):\n",
    "    \n",
    "    dotprod1, h1, dotprod2, output=feedforward(X_test,W1,b1,W2,b2)   \n",
    "    labely_test=y_test\n",
    "    #np.argmax(y_test,axis=1)\n",
    "    labelpred=np.argmax(output,axis=1)\n",
    "    accuracytest = round((accuracy_score(labely_test, labelpred)*100),2)        \n",
    "    print(\"Accuracy on Testing data : {}%\".format(accuracytest))\n",
    "    #return labely_test,labelpred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to measure accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef accuracy(labely_test, labelpred):\\n    accuracytest = round((accuracy_score(labely_test, labelpred)*100),2)        \\n    #print(\"Accuracy : {}%\".format(accuracytest))\\n    return accuracytest\\n    '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def accuracy(labely_test, labelpred):\n",
    "    accuracytest = round((accuracy_score(labely_test, labelpred)*100),2)        \n",
    "    #print(\"Accuracy : {}%\".format(accuracytest))\n",
    "    return accuracytest\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on Validation data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-04516e6f5c9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#accuracy_val=accuracy(labely_test, labelpred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-35796b595d59>\u001b[0m in \u001b[0;36mtesting\u001b[1;34m(W2, b2, W1, b1, X_test, y_test)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#np.argmax(y_test,axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlabelpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0maccuracytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabely_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy on Testing data : {}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#return labely_test,labelpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "accuracy=testing(W2,b2,W1,b1,X_val,y_val)\n",
    "#accuracy_val=accuracy(labely_test, labelpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
